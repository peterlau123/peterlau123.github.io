---
title: "开篇词：AI系统性能工程"
subtitle: "AI系统性能工程读书笔记"
layout: chirpy-post
author: "Peter Lau"
published: true
header-style: text
tags:
  - AI
  - Engineering
---


<div>
  <img class="shadow" src="/img/books/ai_system_perf_engineering/gauge_of_porsche.png" width="500" height="300" alt="Porsche 911 gauge">
</div>



大模型，强在它超乎以往的文里理解能力，大在它的参数体量。通常，强大的能力背后是成本高昂的训练费用，以亿为单位。

AI训练从来靠的不是单点技术，而是从硬件至软件和算法的系统工程。在硬件层面上，你需要关注GPU算力和带宽、 GPU计算节点内的CPU/GPU拓扑，节点间的通信拓扑以及节点与存储的关系；在软件层面上，你需要关注通信库、算子实现、训练框架和对应的优化技术；在算法层面上，你需要关注模型的结构和整个训练流程的搭建。

正如你现在驾驶一辆保时捷超跑，你需要时刻关注仪表盘上面的速度和油耗，合理的调整档位和速度，才能发挥出轿车的卓越性能，享受到愉快的体验。对于AI系统，同样也是。AI训练背后是数以万计的GPU卡组成的集群，每一次训练都伴随着用电功耗和设备检修，可以说是一秒千金。这也正是AI系统性能工程学可以发挥作用的地方。

按照Meta提出的"Goodput"概念，系统工程应直接关注最终的性能表现比如每秒处理Token速度，而不是FLOPS和显存利用率。这些中间状态的数值无法直观转换为机器到底在做多少有意义的活，只能说明机器在忙着，但不完全知道它们在忙啥。有可能它们在传输数据，有可能它们在失败重启，也有可能它们在进行低效冗余的计算。

2025年DeepSeek-R1横空出世，同时伴随着开源一系列的系统工程技术如DeepEP、DeepGEMM、S3和FlashMLA等。它向我们展示了即使在非最优GPU情况下，也可以结合软硬件特点，榨干硬件性能，发挥系统最大潜能。同时，这也证明系统性能工程是很有必要和深入研究的方向。

系统性能工程不是一个单一的学科和技术。正如前面提到，你需要关注的东西比较多。你不一定每一点都非常精通如网络、存储、算子和通信，但是必需要清楚每个方面最关心的点，有相应的数据敏感度，在给定一套配置和性能数据下，能很快判断出系统哪里需要优化，以及优化到什么程度。其实这样来看，AI系统性能工程师更需要技术的广度而非深度，有点类似于架构师的角色。

本文将作为书籍《AI系统性能工程》的开篇词，为后续博客做铺垫。后续博客将记录在阅读本书过程中的思考和总结。