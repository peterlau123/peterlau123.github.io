---
title: "DeepSeek V1"
subtitle: "Internals"
layout: post
author: "Peter Lau"
published: false
header-style: text
tags:
  - Computer science
  - LLM
  - DeepSeek
---


<div>
  <img class="shadow" src="/img/deepseek/DeepSeek-Logo.jpg" width="800" height="250" alt="Transformer Architecture">
</div>


本文主要介绍DeepSeek V1的模型结构。

## Model Architecture

<div>
  <img class="shadow" src="/img/deepseek/deepseek_llm.png" width="500" height="150" alt="Transformer Architecture">
</div>

整体结构借鉴Llama，分别为30和95层，对应参数量7B与67B

$n_{kv\_heads}$指

*Sequence Batch Size*指



## 参考信息

1. [DeepSeek LLM Scaling Open-Source Language Models with Longtermism](https://arxiv.org/pdf/2401.02954)